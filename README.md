## data-science-internship

## Task 1 - Data Pipeline Automation

 Automated data preprocessing, transformation, and loading using Python.

### Tools Used
- Pandas
- Scikit-learn

### Features
- Missing value handling
- Label Encoding
- Feature Scaling
- Train-Test Split

### How to Run
1. Open `data_pipeline.ipynb`
2. Execute the cells step by step


## Task 2 - Deep Learning with TensorFlow

 Built and trained a convolutional neural network (CNN) on the MNIST dataset.

### Tools Used
- TensorFlow
- Keras
- Matplotlib

### Features
- Image preprocessing
- Model training and validation
- Visualization of accuracy and loss

### How to Run
1. Open `deep_learning_mnist.ipynb`
2. Execute all cells

# Task 3 - API Deployment using Flask

 Created an API to serve machine learning predictions in real-time.

### Tools Used
- Flask
- Scikit-learn
- Pickle

### Features
- Model training
- API endpoint for predictions
- JSON input/output

### How to Run
1. Install dependencies: `pip install -r requirements.txt`
2. Run the app: `python app.py`
3. Send POST requests to `/predict` endpoint

## Task 4 - Optimization with PuLP

 Solved a linear programming problem for maximizing profit under constraints.

### Tools Used
- PuLP

### Features
- Decision variables
- Objective function
- Constraints
- Solving and interpreting results

### How to Run
1. Open `optimization_problem.ipynb`
2. Execute all cells




